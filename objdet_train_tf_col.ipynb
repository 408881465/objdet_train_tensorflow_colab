{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "objdet_train_tf_col.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "X0B9vl4EgUL5",
        "Po7E_S4Fg9VB",
        "6iapX5ASCf1s"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Z32c7kIzEYxm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Initialization\n",
        "Check if Colaboratory is empty, if yes, go to next step, if not, kill vm instance and reopen notebook"
      ]
    },
    {
      "metadata": {
        "id": "wvnMZESjepx4",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!ls -l"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "a1E-NoMLmB0P",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O4OBNvlruMAa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Install required libraries"
      ]
    },
    {
      "metadata": {
        "id": "91G1B1lTwp9b",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get install -y -qq protobuf-compiler python-pil python-lxml libsm6 libxext6 && pip install -q -U opencv-python"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9TA4y5cITMNK",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!git clone --quiet https://github.com/tensorflow/models.git tensorflow_models"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "7KLYnulgTdwV",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cd tensorflow_models/research"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kkCxkiPDTpbk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!protoc object_detection/protos/*.proto --python_out=."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Kj6y69fmT22C",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import sys\n",
        "sys.path.append('/content/tensorflow_models/research')\n",
        "sys.path.append('/content/tensorflow_models/research/slim')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rl1Tq2zxU8PN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "cd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QyZLyPQkTTAK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Upload from Google Drive (substitute 3 next uploading steps)\n",
        "Generic zip file upload from Google Drive, in case of needs. Set Google Drive (fileId, unzipDir) into fileIdUnzipDirList to upload and unzip it."
      ]
    },
    {
      "metadata": {
        "id": "iZH-j6suTioY",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install -U -q PyDrive\n",
        "\n",
        "fileIdUnzipDirList = [('19PSIC2rtps2r5DHwqTEUtRlccpaKZW4V', 'images'), ('1SuSic7drlmOaHvLoEj9QXY-ai5e3ftK7', 'model'), ('12MqnYTyueAu4cJx9IpN3aZy6qbqLnJ1_','annotations')]\n",
        "\n",
        "import os\n",
        "from zipfile import ZipFile\n",
        "from shutil import rmtree\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "fileName = 'downloaded.zip'\n",
        "for fileId, unzipDir in fileIdUnzipDirList:\n",
        "    downloaded = drive.CreateFile({'id': fileId})\n",
        "    downloaded.GetContentFile(fileName)\n",
        "    print('Downloaded file id: ' + fileId + ' with file name: ' + fileName)\n",
        "\n",
        "    if os.path.isdir(unzipDir):\n",
        "        rmtree(unzipDir)\n",
        "    os.mkdir(unzipDir)\n",
        "    ds = ZipFile(fileName)\n",
        "    ds.extractall(unzipDir)\n",
        "    os.remove(fileName)\n",
        "    print('Extracted zip file ' + fileName + ' in directory: ' + unzipDir)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X0B9vl4EgUL5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import training image dataset\n",
        "In the next cell upload a zip file, containing files in .jpg format"
      ]
    },
    {
      "metadata": {
        "id": "h-9qVhEpgNJU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "from shutil import rmtree\n",
        "import os\n",
        "\n",
        "datadir = 'images'\n",
        "if os.path.isdir(datadir):\n",
        "  rmtree(datadir)\n",
        "os.mkdir(datadir)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open(name, 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)\n",
        "    ds = ZipFile(name)\n",
        "    ds.extractall(datadir)\n",
        "    print('extracted file ' + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Po7E_S4Fg9VB",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import training annotation files, created with LabelImg\n",
        "In the next cell upload a zip file, containing files in .xml format"
      ]
    },
    {
      "metadata": {
        "id": "F73aMeq1hcqm",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "from shutil import rmtree\n",
        "import os\n",
        "\n",
        "datadir = 'annotations'\n",
        "if os.path.isdir(datadir):\n",
        "  rmtree(datadir)\n",
        "os.mkdir(datadir)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open(name, 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)\n",
        "    ds = ZipFile(name)\n",
        "    ds.extractall(datadir)\n",
        "    print('extracted file ' + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6iapX5ASCf1s",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Import model and config file from ModelZoo\n",
        "In the next cell upload a zip file, containing 4 files:\n",
        "* 3 files from pretrained models in ModelZoo: model.ckpt.data-00000-of-00001 model.ckpt.index model.ckpt.meta\n",
        "* 1 config file pets version (i.e. faster_rcnn_inception_v2_pets.config) from https://github.com/tensorflow/models/tree/master/research/object_detection/samples/configs"
      ]
    },
    {
      "metadata": {
        "id": "JnhIT-FgDRsb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from zipfile import ZipFile\n",
        "from shutil import rmtree\n",
        "import os\n",
        "\n",
        "datadir = 'model'\n",
        "if os.path.isdir(datadir):\n",
        "  rmtree(datadir)\n",
        "os.mkdir(datadir)\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(name=fn, length=len(uploaded[fn])))\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open(name, 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)\n",
        "    ds = ZipFile(name)\n",
        "    ds.extractall(datadir)\n",
        "    print('extracted file ' + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GII9h0dVvCUM",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create labels.csv from xml annotation files"
      ]
    },
    {
      "metadata": {
        "id": "_x53lPBpfr2A",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import pandas as pd\n",
        "import xml.etree.ElementTree as ET\n",
        "\n",
        "\n",
        "def xml_to_csv(path):\n",
        "    xml_list = []\n",
        "    for xml_file in glob.glob(path + '/*.xml'):\n",
        "        tree = ET.parse(xml_file)\n",
        "        root = tree.getroot()\n",
        "        for member in root.findall('object'):\n",
        "            value = (root.find('filename').text,\n",
        "                     int(root.find('size')[0].text),\n",
        "                     int(root.find('size')[1].text),\n",
        "                     member[0].text,\n",
        "                     int(member[4][0].text),\n",
        "                     int(member[4][1].text),\n",
        "                     int(member[4][2].text),\n",
        "                     int(member[4][3].text)\n",
        "                     )\n",
        "            xml_list.append(value)\n",
        "    column_name = ['filename', 'width', 'height', 'class', 'xmin', 'ymin', 'xmax', 'ymax']\n",
        "    xml_df = pd.DataFrame(xml_list, columns=column_name)\n",
        "    return xml_df\n",
        "\n",
        "\n",
        "def main():\n",
        "    datadir = 'data'\n",
        "    if os.path.isdir(datadir):\n",
        "        rmtree(datadir)\n",
        "    os.mkdir(datadir)\n",
        "    image_path = 'annotations'\n",
        "    xml_df = xml_to_csv(image_path)\n",
        "    xml_df.to_csv('data/labels.csv', index=None)\n",
        "    print('Successfully converted xml to csv.')\n",
        "\n",
        "\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vElzX3zDE5JQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Split labels between train and test data\n",
        "Every 10 lines we split 80% of labels for training and 20% for test"
      ]
    },
    {
      "metadata": {
        "id": "P1iRLAqjzZ_7",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open('data/labels.csv', 'r') as f_in:\n",
        "  f_train =  open('data/train_labels.csv', 'w')\n",
        "  f_test =  open('data/test_labels.csv', 'w')\n",
        "\n",
        "  first_line = f_in.readline()\n",
        "  f_train.write(first_line)\n",
        "  f_test.write(first_line)\n",
        "    \n",
        "  for line_number, line in enumerate(f_in):\n",
        "    if line_number % 10 < 8:\n",
        "      f_train.write(line)\n",
        "    else:\n",
        "      f_test.write(line)\n",
        "\n",
        "  f_train.close()\n",
        "  f_test.close()\n",
        "  \n",
        "print('Successfully created train and test labels files.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "otN82JWFP76Q",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create labels class files: labels.csv and label_map.pbtxt"
      ]
    },
    {
      "metadata": {
        "id": "16KGqw9nv4Cf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import json\n",
        "\n",
        "labels = pd.read_csv('data/labels.csv', delimiter=',')\n",
        "classes = labels['class'].unique()\n",
        "\n",
        "with open('data/classes.csv', 'w') as f:\n",
        "    for s in classes:\n",
        "        f.write(str(s) +',')\n",
        "\n",
        "with open('data/label_map.pbtxt', 'w') as f:\n",
        "    index_classes = ''\n",
        "    for line_number, line in enumerate(classes):\n",
        "        index_classes += \"item {\\n  id: \" + str(line_number + 1) + \"\\n  name: '\" + line + \"'\\n}\\n\"\n",
        "    f.write(index_classes)\n",
        "\n",
        "print('Successfully created classes files.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iSadSQrVSzoR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Create train and test data files"
      ]
    },
    {
      "metadata": {
        "id": "kM2iueF99gtb",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "from __future__ import absolute_import\n",
        "\n",
        "import os\n",
        "import io\n",
        "import pandas as pd\n",
        "import csv\n",
        "import tensorflow as tf\n",
        "\n",
        "from PIL import Image\n",
        "from object_detection.utils import dataset_util\n",
        "from collections import namedtuple, OrderedDict\n",
        "\n",
        "flags = tf.app.flags\n",
        "# flags.DEFINE_string('csv_input', '', 'Path to the CSV input')\n",
        "# flags.DEFINE_string('output_path', '', 'Path to output TFRecord')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "label_files = ['data/train_labels.csv', 'data/test_labels.csv']\n",
        "output_files = ['data/train.record', 'data/test.record']\n",
        "\n",
        "\n",
        "def class_text_to_int(row_label):\n",
        "    with open('data/classes.csv', 'r') as classes_file:\n",
        "        classes_list = classes_file.readline().split(',')\n",
        "    index = classes_list.index(row_label) + 1\n",
        "    return index\n",
        "\n",
        "    \n",
        "def split(df, group):\n",
        "    data = namedtuple('data', ['filename', 'object'])\n",
        "    gb = df.groupby(group)\n",
        "    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n",
        "\n",
        "\n",
        "def create_tf_example(group, path):\n",
        "    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n",
        "        encoded_jpg = fid.read()\n",
        "    encoded_jpg_io = io.BytesIO(encoded_jpg)\n",
        "    image = Image.open(encoded_jpg_io)\n",
        "    width, height = image.size\n",
        "\n",
        "    filename = group.filename.encode('utf8')\n",
        "    image_format = b'jpg'\n",
        "    xmins = []\n",
        "    xmaxs = []\n",
        "    ymins = []\n",
        "    ymaxs = []\n",
        "    classes_text = []\n",
        "    classes = []\n",
        "\n",
        "    for index, row in group.object.iterrows():\n",
        "        xmins.append(row['xmin'] / width)\n",
        "        xmaxs.append(row['xmax'] / width)\n",
        "        ymins.append(row['ymin'] / height)\n",
        "        ymaxs.append(row['ymax'] / height)\n",
        "        classes_text.append(row['class'].encode('utf8'))\n",
        "        classes.append(class_text_to_int(row['class']))\n",
        "\n",
        "    tf_example = tf.train.Example(features=tf.train.Features(feature={\n",
        "        'image/height': dataset_util.int64_feature(height),\n",
        "        'image/width': dataset_util.int64_feature(width),\n",
        "        'image/filename': dataset_util.bytes_feature(filename),\n",
        "        'image/source_id': dataset_util.bytes_feature(filename),\n",
        "        'image/encoded': dataset_util.bytes_feature(encoded_jpg),\n",
        "        'image/format': dataset_util.bytes_feature(image_format),\n",
        "        'image/object/bbox/xmin': dataset_util.float_list_feature(xmins),\n",
        "        'image/object/bbox/xmax': dataset_util.float_list_feature(xmaxs),\n",
        "        'image/object/bbox/ymin': dataset_util.float_list_feature(ymins),\n",
        "        'image/object/bbox/ymax': dataset_util.float_list_feature(ymaxs),\n",
        "        'image/object/class/text': dataset_util.bytes_list_feature(classes_text),\n",
        "        'image/object/class/label': dataset_util.int64_list_feature(classes),\n",
        "    }))\n",
        "    return tf_example\n",
        "\n",
        "\n",
        "def main():\n",
        "  for i in range(len(label_files)):\n",
        "    writer = tf.python_io.TFRecordWriter(output_files[i])\n",
        "    path = os.path.join(os.getcwd(), 'images')\n",
        "    examples = pd.read_csv(label_files[i])\n",
        "    grouped = split(examples, 'filename')\n",
        "    for group in grouped:\n",
        "        tf_example = create_tf_example(group, path)\n",
        "        writer.write(tf_example.SerializeToString())\n",
        "\n",
        "    writer.close()\n",
        "    output_path = os.path.join(os.getcwd(), output_files[i])\n",
        "    print('Successfully created the TFRecords: {}'.format(output_path))\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#    tf.app.run()\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAYqMDCeKutp",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Edit config file to set num_classes\n",
        "It must to be = classes number"
      ]
    },
    {
      "metadata": {
        "id": "3S33Y6GpK8TI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "filename = 'model/faster_rcnn_inception_v2_pets.config'\n",
        "\n",
        "with open('data/classes.csv', 'r') as classes_file:\n",
        "    classes_list = classes_file.readline().split(',')\n",
        "classes_number = len(classes_list) - 1\n",
        "\n",
        "with open(filename, 'r') as f:\n",
        "    s = f.read()\n",
        "with open(filename, 'w') as f:\n",
        "    s = re.sub('num_classes: [0-9]+', 'num_classes: ' + str(classes_number), s)\n",
        "    f.write(s)\n",
        "    \n",
        "print('Finished set num_classes: ' + str(classes_number))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JYR7Ituv1oRC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Further settings of config file\n",
        "If you use other config file then proposed, edit file to set PATH_TO_BE_CONFIGURED:\n",
        "* fine_tune_checkpoint: \"./model/model.ckpt\"\n",
        "* input_path: \"./data/train.record\"\n",
        "* label_map_path: \"./data/label_map.pbtxt\"\t\n",
        "* input_path: \"./data/test.record\"\n",
        "* label_map_path: \"./data/label_map.pbtxt\"\n"
      ]
    },
    {
      "metadata": {
        "id": "7M_KQedj3j_j",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train model"
      ]
    },
    {
      "metadata": {
        "id": "Dij8wKxX3mrI",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Training executable for detection models.\n",
        "\n",
        "This executable is used to train DetectionModels. There are two ways of\n",
        "configuring the training job:\n",
        "\n",
        "1) A single pipeline_pb2.TrainEvalPipelineConfig configuration file\n",
        "can be specified by --pipeline_config_path.\n",
        "\n",
        "Example usage:\n",
        "    ./train \\\n",
        "        --logtostderr \\\n",
        "        --train_dir=path/to/train_dir \\\n",
        "        --pipeline_config_path=pipeline_config.pbtxt\n",
        "\n",
        "2) Three configuration files can be provided: a model_pb2.DetectionModel\n",
        "configuration file to define what type of DetectionModel is being trained, an\n",
        "input_reader_pb2.InputReader file to specify what training data will be used and\n",
        "a train_pb2.TrainConfig file to configure training parameters.\n",
        "\n",
        "Example usage:\n",
        "    ./train \\\n",
        "        --logtostderr \\\n",
        "        --train_dir=path/to/train_dir \\\n",
        "        --model_config_path=model_config.pbtxt \\\n",
        "        --train_config_path=train_config.pbtxt \\\n",
        "        --input_config_path=train_input_config.pbtxt\n",
        "\"\"\"\n",
        "\n",
        "import functools\n",
        "import json\n",
        "import os\n",
        "import tensorflow as tf\n",
        "\n",
        "from object_detection import trainer\n",
        "from object_detection.builders import dataset_builder\n",
        "from object_detection.builders import model_builder\n",
        "from object_detection.utils import config_util\n",
        "from object_detection.utils import dataset_util\n",
        "\n",
        "tf.logging.set_verbosity(tf.logging.INFO)\n",
        "\n",
        "flags = tf.app.flags\n",
        "#flags.DEFINE_string('master', '', 'Name of the TensorFlow master to use.')\n",
        "FLAGS_master = ''\n",
        "#flags.DEFINE_integer('task', 0, 'task id')\n",
        "FLAGS_task = 0\n",
        "#flags.DEFINE_integer('num_clones', 1, 'Number of clones to deploy per worker.')\n",
        "FLAGS_num_clones = 1\n",
        "#flags.DEFINE_boolean('clone_on_cpu', False,\n",
        "#                     'Force clones to be deployed on CPU.  Note that even if '\n",
        "#                     'set to False (allowing ops to run on gpu), some ops may '\n",
        "#                     'still be run on the CPU if they have no GPU kernel.')\n",
        "FLAGS_clone_on_cpu = False\n",
        "#flags.DEFINE_integer('worker_replicas', 1, 'Number of worker+trainer '\n",
        "#                     'replicas.')\n",
        "FLAGS_worker_replicas = 1\n",
        "#flags.DEFINE_integer('ps_tasks', 0,\n",
        "#                     'Number of parameter server tasks. If None, does not use '\n",
        "#                     'a parameter server.')\n",
        "FLAGS_ps_tasks = 0\n",
        "#flags.DEFINE_string('train_dir', '',\n",
        "#                    'Directory to save the checkpoints and training summaries.')\n",
        "FLAGS_train_dir = 'data/train'\n",
        "#flags.DEFINE_string('pipeline_config_path', '',\n",
        "#                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "#                    'file. If provided, other configs are ignored')\n",
        "FLAGS_pipeline_config_path = 'model/faster_rcnn_inception_v2_pets.config'\n",
        "#flags.DEFINE_string('train_config_path', '',\n",
        "#                    'Path to a train_pb2.TrainConfig config file.')\n",
        "FLAGS_train_config_path = ''\n",
        "#flags.DEFINE_string('input_config_path', '',\n",
        "#                    'Path to an input_reader_pb2.InputReader config file.')\n",
        "FLAGS_input_config_path = ''\n",
        "#flags.DEFINE_string('model_config_path', '',\n",
        "#                    'Path to a model_pb2.DetectionModel config file.')\n",
        "FLAGS_model_config_path = ''\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main():\n",
        "  assert FLAGS_train_dir, '`train_dir` is missing.'\n",
        "  if FLAGS_task == 0: tf.gfile.MakeDirs(FLAGS_train_dir)\n",
        "  if FLAGS_pipeline_config_path:\n",
        "    configs = config_util.get_configs_from_pipeline_file(\n",
        "        FLAGS_pipeline_config_path)\n",
        "    if FLAGS_task == 0:\n",
        "      tf.gfile.Copy(FLAGS_pipeline_config_path,\n",
        "                    os.path.join(FLAGS_train_dir, 'pipeline.config'),\n",
        "                    overwrite=True)\n",
        "  else:\n",
        "    configs = config_util.get_configs_from_multiple_files(\n",
        "        model_config_path=FLAGS_model_config_path,\n",
        "        train_config_path=FLAGS_train_config_path,\n",
        "        train_input_config_path=FLAGS_input_config_path)\n",
        "    if FLAGS_task == 0:\n",
        "      for name, config in [('model.config', FLAGS_model_config_path),\n",
        "                           ('train.config', FLAGS_train_config_path),\n",
        "                           ('input.config', FLAGS_input_config_path)]:\n",
        "        tf.gfile.Copy(config, os.path.join(FLAGS_train_dir, name),\n",
        "                      overwrite=True)\n",
        "\n",
        "  model_config = configs['model']\n",
        "  train_config = configs['train_config']\n",
        "  input_config = configs['train_input_config']\n",
        "\n",
        "  model_fn = functools.partial(\n",
        "      model_builder.build,\n",
        "      model_config=model_config,\n",
        "      is_training=True)\n",
        "\n",
        "  def get_next(config):\n",
        "    return dataset_util.make_initializable_iterator(\n",
        "      dataset_builder.build(config)).get_next()\n",
        "\n",
        "  create_input_dict_fn = functools.partial(get_next, input_config)\n",
        "\n",
        "  env = json.loads(os.environ.get('TF_CONFIG', '{}'))\n",
        "  cluster_data = env.get('cluster', None)\n",
        "  cluster = tf.train.ClusterSpec(cluster_data) if cluster_data else None\n",
        "  task_data = env.get('task', None) or {'type': 'master', 'index': 0}\n",
        "  task_info = type('TaskSpec', (object,), task_data)\n",
        "\n",
        "  # Parameters for a single worker.\n",
        "  ps_tasks = 0\n",
        "  worker_replicas = 1\n",
        "  worker_job_name = 'lonely_worker'\n",
        "  task = 0\n",
        "  is_chief = True\n",
        "  master = ''\n",
        "\n",
        "  if cluster_data and 'worker' in cluster_data:\n",
        "    # Number of total worker replicas include \"worker\"s and the \"master\".\n",
        "    worker_replicas = len(cluster_data['worker']) + 1\n",
        "  if cluster_data and 'ps' in cluster_data:\n",
        "    ps_tasks = len(cluster_data['ps'])\n",
        "\n",
        "  if worker_replicas > 1 and ps_tasks < 1:\n",
        "    raise ValueError('At least 1 ps task is needed for distributed training.')\n",
        "\n",
        "  if worker_replicas >= 1 and ps_tasks > 0:\n",
        "    # Set up distributed training.\n",
        "    server = tf.train.Server(tf.train.ClusterSpec(cluster), protocol='grpc',\n",
        "                             job_name=task_info.type,\n",
        "                             task_index=task_info.index)\n",
        "    if task_info.type == 'ps':\n",
        "      server.join()\n",
        "      return\n",
        "\n",
        "    worker_job_name = '%s/task:%d' % (task_info.type, task_info.index)\n",
        "    task = task_info.index\n",
        "    is_chief = (task_info.type == 'master')\n",
        "    master = server.target\n",
        "\n",
        "  trainer.train(create_input_dict_fn, model_fn, train_config, master, task,\n",
        "                FLAGS_num_clones, worker_replicas, FLAGS_clone_on_cpu, ps_tasks,\n",
        "                worker_job_name, is_chief, FLAGS_train_dir)\n",
        "\n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#  tf.app.run()\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z3JFK6Lb-tj8",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Export trained model"
      ]
    },
    {
      "metadata": {
        "id": "cLuxGF2h-ofe",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# Copyright 2017 The TensorFlow Authors. All Rights Reserved.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\n",
        "r\"\"\"Tool to export an object detection model for inference.\n",
        "\n",
        "Prepares an object detection tensorflow graph for inference using model\n",
        "configuration and an optional trained checkpoint. Outputs inference\n",
        "graph, associated checkpoint files, a frozen inference graph and a\n",
        "SavedModel (https://tensorflow.github.io/serving/serving_basic.html).\n",
        "\n",
        "The inference graph contains one of three input nodes depending on the user\n",
        "specified option.\n",
        "  * `image_tensor`: Accepts a uint8 4-D tensor of shape [None, None, None, 3]\n",
        "  * `encoded_image_string_tensor`: Accepts a 1-D string tensor of shape [None]\n",
        "    containing encoded PNG or JPEG images. Image resolutions are expected to be\n",
        "    the same if more than 1 image is provided.\n",
        "  * `tf_example`: Accepts a 1-D string tensor of shape [None] containing\n",
        "    serialized TFExample protos. Image resolutions are expected to be the same\n",
        "    if more than 1 image is provided.\n",
        "\n",
        "and the following output nodes returned by the model.postprocess(..):\n",
        "  * `num_detections`: Outputs float32 tensors of the form [batch]\n",
        "      that specifies the number of valid boxes per image in the batch.\n",
        "  * `detection_boxes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, 4] containing detected boxes.\n",
        "  * `detection_scores`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing class scores for the detections.\n",
        "  * `detection_classes`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes] containing classes for the detections.\n",
        "  * `detection_masks`: Outputs float32 tensors of the form\n",
        "      [batch, num_boxes, mask_height, mask_width] containing predicted instance\n",
        "      masks for each box if its present in the dictionary of postprocessed\n",
        "      tensors returned by the model.\n",
        "\n",
        "Notes:\n",
        " * This tool uses `use_moving_averages` from eval_config to decide which\n",
        "   weights to freeze.\n",
        "\n",
        "Example Usage:\n",
        "--------------\n",
        "python export_inference_graph \\\n",
        "    --input_type image_tensor \\\n",
        "    --pipeline_config_path path/to/ssd_inception_v2.config \\\n",
        "    --trained_checkpoint_prefix path/to/model.ckpt \\\n",
        "    --output_directory path/to/exported_model_directory\n",
        "\n",
        "The expected output would be in the directory\n",
        "path/to/exported_model_directory (which is created if it does not exist)\n",
        "with contents:\n",
        " - graph.pbtxt\n",
        " - model.ckpt.data-00000-of-00001\n",
        " - model.ckpt.info\n",
        " - model.ckpt.meta\n",
        " - frozen_inference_graph.pb\n",
        " + saved_model (a directory)\n",
        "\"\"\"\n",
        "import tensorflow as tf\n",
        "from google.protobuf import text_format\n",
        "from object_detection import exporter\n",
        "from object_detection.protos import pipeline_pb2\n",
        "\n",
        "slim = tf.contrib.slim\n",
        "flags = tf.app.flags\n",
        "\n",
        "import glob\n",
        "newest = max(glob.iglob('data/train/model.ckpt*.meta'), key=os.path.getctime)\n",
        "model_prefix = newest[:newest.rfind('.')]\n",
        "print ('Model_prefix: ' + model_prefix)\n",
        "\n",
        "#flags.DEFINE_string('input_type', 'image_tensor', 'Type of input node. Can be '\n",
        "#                    'one of [`image_tensor`, `encoded_image_string_tensor`, '\n",
        "#                    '`tf_example`]')\n",
        "FLAGS_input_type = 'image_tensor'\n",
        "#flags.DEFINE_string('input_shape', None,\n",
        "#                    'If input_type is `image_tensor`, this can explicitly set '\n",
        "#                    'the shape of this input tensor to a fixed size. The '\n",
        "#                    'dimensions are to be provided as a comma-separated list '\n",
        "#                    'of integers. A value of -1 can be used for unknown '\n",
        "#                    'dimensions. If not specified, for an `image_tensor, the '\n",
        "#                    'default shape will be partially specified as '\n",
        "#                    '`[None, None, None, 3]`.')\n",
        "FLAGS_input_shape = None\n",
        "#flags.DEFINE_string('pipeline_config_path', None,\n",
        "#                    'Path to a pipeline_pb2.TrainEvalPipelineConfig config '\n",
        "#                    'file.')\n",
        "FLAGS_pipeline_config_path = 'model/faster_rcnn_inception_v2_pets.config'\n",
        "#flags.DEFINE_string('trained_checkpoint_prefix', None,\n",
        "#                    'Path to trained checkpoint, typically of the form '\n",
        "#                    'path/to/model.ckpt')\n",
        "FLAGS_trained_checkpoint_prefix  = model_prefix\n",
        "#flags.DEFINE_string('output_directory', None, 'Path to write outputs.')\n",
        "FLAGS_output_directory = 'data/fine_tuned_model'\n",
        "\n",
        "#tf.app.flags.mark_flag_as_required('pipeline_config_path')\n",
        "#tf.app.flags.mark_flag_as_required('trained_checkpoint_prefix')\n",
        "#tf.app.flags.mark_flag_as_required('output_directory')\n",
        "FLAGS = flags.FLAGS\n",
        "\n",
        "\n",
        "def main():\n",
        "  pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
        "  with tf.gfile.GFile(FLAGS_pipeline_config_path, 'r') as f:\n",
        "    text_format.Merge(f.read(), pipeline_config)\n",
        "  if FLAGS_input_shape:\n",
        "    input_shape = [\n",
        "        int(dim) if dim != '-1' else None\n",
        "        for dim in FLAGS_input_shape.split(',')\n",
        "    ]\n",
        "  else:\n",
        "    input_shape = None\n",
        "  exporter.export_inference_graph(FLAGS_input_type, pipeline_config,\n",
        "                                  FLAGS_trained_checkpoint_prefix,\n",
        "                                  FLAGS_output_directory, input_shape)\n",
        "  print ('Model export complete in: ' + FLAGS_output_directory)\n",
        "  \n",
        "\n",
        "#if __name__ == '__main__':\n",
        "#  tf.app.run()\n",
        "main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wDEY7rmQE7nQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#Upload jpg image to execute object detection"
      ]
    },
    {
      "metadata": {
        "id": "oI8Ya_6GE9ll",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "from os import path\n",
        "\n",
        "uploaded = files.upload()\n",
        "  \n",
        "for name, data in uploaded.items():\n",
        "  with open('img.jpg', 'wb') as f:\n",
        "    f.write(data)\n",
        "    f.close()\n",
        "    print('saved file ' + name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WAjsbz7GzOzk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Execute object detection"
      ]
    },
    {
      "metadata": {
        "id": "s1-x_lGczR_R",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import six.moves.urllib as urllib\n",
        "import sys\n",
        "import tarfile\n",
        "import tensorflow as tf\n",
        "import zipfile\n",
        "import argparse\n",
        "import cv2\n",
        "\n",
        "from collections import defaultdict\n",
        "from io import StringIO\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "from object_detection.utils import label_map_util\n",
        "from object_detection.utils import visualization_utils as vis_util\n",
        "\n",
        "\n",
        "PATH_TO_CKPT = 'data/fine_tuned_model/frozen_inference_graph.pb'\n",
        "PATH_TO_LABELS = 'data/label_map.pbtxt'\n",
        "\n",
        "TEST_IMAGE_PATHS = 'img.jpg'\n",
        "IMAGE_SIZE = (12, 8)\n",
        "\n",
        "\n",
        "with open(PATH_TO_LABELS, 'r') as classes_file:\n",
        "    content = classes_file.read()\n",
        "num_classes = content.count('item {')\n",
        "print('Set num_classes: ' + str(num_classes))\n",
        "\n",
        "a = argparse.ArgumentParser()\n",
        "a.add_argument(\"--image\", default=\"img.jpg\", help=\"path to image\")\n",
        "args = a.parse_args([])\n",
        "image_np = cv2.imread(args.image)\n",
        "\n",
        "detection_graph = tf.Graph()\n",
        "with detection_graph.as_default():\n",
        "  od_graph_def = tf.GraphDef()\n",
        "  with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n",
        "    serialized_graph = fid.read()\n",
        "    od_graph_def.ParseFromString(serialized_graph)\n",
        "    tf.import_graph_def(od_graph_def, name='')\n",
        "\n",
        "label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n",
        "categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=num_classes, use_display_name=True)\n",
        "category_index = label_map_util.create_category_index(categories)\n",
        "\n",
        "def load_image_into_numpy_array(image):\n",
        "  (im_width, im_height) = image.size\n",
        "  return np.array(image.getdata()).reshape(\n",
        "      (im_height, im_width, 3)).astype(np.uint8)\n",
        "\n",
        "\n",
        "with detection_graph.as_default():\n",
        "  #DISABLE GPU IF OOM ERROR\n",
        "#  config = tf.ConfigProto(device_count = {'GPU': 0})\n",
        "#  with tf.Session(config=config, graph=detection_graph) as sess:\n",
        "  with tf.Session(graph=detection_graph) as sess:\n",
        "    image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n",
        "    detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n",
        "    detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n",
        "    detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n",
        "    num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n",
        "    image_np_expanded = np.expand_dims(image_np, axis=0)\n",
        "    (boxes, scores, classes, num) = sess.run(\n",
        "        [detection_boxes, detection_scores, detection_classes, num_detections],\n",
        "        feed_dict={image_tensor: image_np_expanded})\n",
        "    vis_util.visualize_boxes_and_labels_on_image_array(\n",
        "        image_np,\n",
        "        np.squeeze(boxes),\n",
        "        np.squeeze(classes).astype(np.int32),\n",
        "        np.squeeze(scores),\n",
        "        category_index,\n",
        "        use_normalized_coordinates=True,\n",
        "        line_thickness=8)\n",
        "\n",
        "    img_result = 'result.jpg'\n",
        "    cv2.imwrite(img_result, cv2.resize(image_np, (800,600)))\n",
        "    display(Image.open(img_result))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s8shLEMsDTAL",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Export trained model"
      ]
    },
    {
      "metadata": {
        "id": "yvo81_67DVvo",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "files.download('data/label_map.pbtxt')\n",
        "files.download('data/fine_tuned_model/frozen_inference_graph.pb')\n",
        "\n",
        "print('Downloaded model files')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}